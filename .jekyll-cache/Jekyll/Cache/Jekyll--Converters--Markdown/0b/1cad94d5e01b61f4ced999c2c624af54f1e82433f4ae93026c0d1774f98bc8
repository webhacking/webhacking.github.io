I"<p><a href="http://www.wixsoft.com/">íŒ€</a>ì—ì„œ ê²€ìƒ‰ì—”ì§„ë•Œë¬¸ì— ìë£Œë¥¼ ì°¾ê³ ìˆë‹¤ê°€ êµ¬ê¸€ ì´ë¯¸ì§€ ê²€ìƒ‰ì—”ì§„ì´ ê¶ê¸ˆí•´ì„œ ìë£Œë¥¼ ì°¾ì•„ë´¤ë‹¤.</p>

<p>My guess is that Google probably uses some combination of the following
techniques and ranks the results using a proprietary algorithm.</p>

<p><strong>Feature Detection (Image fingerprinting to look for exact match) &amp; Search by Color &amp; Visual Similarity Search</strong></p>

<p>There are three commonly used feature detection algorithms for matching image
deformation such as blur, rotation, scale, and illumination change.</p>

<p>They are SIFT, PCA-SIFT and SURF</p>

<ul>
  <li>SIFT is slow and not good at illumination changes, while it is invariant to rotation, scale changes and affine transformations.</li>
  <li>SURF is fast and has good performance as the same as SIFT, but it is not stable to rotation and illumination changes.</li>
  <li>PCA-SIFT is the best but it has problems with image blur.</li>
</ul>

<p>There is no perfect algorithm, so the choice depends mainly on the
application, and what kind of trade-offs the application can tolerate.</p>

<p>Example: PixID http://ideeinc.com/products/pixid/</p>

<p>ë”ë³´ê¸° : https://www.quora.com/What-is-the-algorithm-used-by-Google-Search-by-
Image-1</p>

:ET